{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "9ffce314",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import datetime\n",
    "import dateparser\n",
    "import numpy as np\n",
    "from dotenv import load_dotenv\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "import string\n",
    "\n",
    "from pydantic import BaseModel, Field, field_validator\n",
    "from typing import List, Optional, get_origin, get_args, Union\n",
    "from langchain.output_parsers import PydanticOutputParser\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI, GoogleGenerativeAIEmbeddings\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain.output_parsers import ResponseSchema, StructuredOutputParser\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import ArrayType, StringType, IntegerType, FloatType, BooleanType, TimestampType, StructField, StructType"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe5b16a7",
   "metadata": {},
   "source": [
    "# SOURCE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e191b92b",
   "metadata": {},
   "source": [
    "Import from Huggingface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d9707e7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "splits = {'train': 'train.csv', 'test': 'test.csv'}\n",
    "df = pd.read_csv(\"hf://datasets/cnamuangtoun/resume-job-description-fit/\" + splits[\"train\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b14ada8",
   "metadata": {},
   "source": [
    "Generate random snapshot dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "c7a9971d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a seeded Generator\n",
    "rng = np.random.default_rng(seed=42)\n",
    "\n",
    "# Define start and end date\n",
    "start_date = pd.to_datetime('2024-01-01')\n",
    "end_date = pd.to_datetime('2025-01-01')\n",
    "\n",
    "# Generate random timestamps between start_date and end_date\n",
    "random_dates = pd.to_datetime(\n",
    "    rng.uniform(start_date.value, end_date.value, size=len(df))\n",
    ")\n",
    "\n",
    "# Ensure it's treated as a pandas Series and convert to date\n",
    "df['snapshot_date'] = pd.Series(random_dates).dt.date  # This will convert to date format"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb271e43",
   "metadata": {},
   "source": [
    "Generate random IDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "13c86898",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_random_id(prefix: str, length=8, use_digits=True, use_letters=True, seed=42):\n",
    "    rng = np.random.default_rng(seed=seed) \n",
    "\n",
    "    characters = ''\n",
    "    \n",
    "    if use_digits:\n",
    "        characters += string.digits\n",
    "    if use_letters:\n",
    "        characters += string.ascii_letters\n",
    "\n",
    "    # Ensure we have characters to choose from\n",
    "    if not characters:\n",
    "        raise ValueError(\"At least one of 'use_digits' or 'use_letters' must be True.\")\n",
    "    \n",
    "    # Use np.random.choice to randomly select characters\n",
    "    random_id = ''.join(rng.choice(list(characters), size=length))\n",
    "    return prefix + random_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "86cc74a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['resume_id'] = df.apply(lambda row: generate_random_id('RES_', seed=row.name), axis=1)\n",
    "df['job_id'] = df.apply(lambda row: generate_random_id('JD_', seed=row.name), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f4750cc",
   "metadata": {},
   "source": [
    "Setup env & pyspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cf38c501",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "os.environ[\"GOOGLE_API_KEY\"] = os.getenv(\"GOOGLE_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a3db7a17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ":: loading settings :: url = jar:file:/usr/local/lib/python3.12/site-packages/pyspark/jars/ivy-2.5.1.jar!/org/apache/ivy/core/settings/ivysettings.xml\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ivy Default Cache set to: /root/.ivy2/cache\n",
      "The jars for the packages stored in: /root/.ivy2/jars\n",
      "org.mongodb.spark#mongo-spark-connector_2.12 added as a dependency\n",
      ":: resolving dependencies :: org.apache.spark#spark-submit-parent-8802c274-e71f-489b-8925-31333f629444;1.0\n",
      "\tconfs: [default]\n",
      "\tfound org.mongodb.spark#mongo-spark-connector_2.12;10.5.0 in central\n",
      "\tfound org.mongodb#mongodb-driver-sync;5.1.4 in central\n",
      "\t[5.1.4] org.mongodb#mongodb-driver-sync;[5.1.1,5.1.99)\n",
      "\tfound org.mongodb#bson;5.1.4 in central\n",
      "\tfound org.mongodb#mongodb-driver-core;5.1.4 in central\n",
      "\tfound org.mongodb#bson-record-codec;5.1.4 in central\n",
      "downloading https://repo1.maven.org/maven2/org/mongodb/spark/mongo-spark-connector_2.12/10.5.0/mongo-spark-connector_2.12-10.5.0.jar ...\n",
      "\t[SUCCESSFUL ] org.mongodb.spark#mongo-spark-connector_2.12;10.5.0!mongo-spark-connector_2.12.jar (902ms)\n",
      "downloading https://repo1.maven.org/maven2/org/mongodb/mongodb-driver-sync/5.1.4/mongodb-driver-sync-5.1.4.jar ...\n",
      "\t[SUCCESSFUL ] org.mongodb#mongodb-driver-sync;5.1.4!mongodb-driver-sync.jar (480ms)\n",
      "downloading https://repo1.maven.org/maven2/org/mongodb/bson/5.1.4/bson-5.1.4.jar ...\n",
      "\t[SUCCESSFUL ] org.mongodb#bson;5.1.4!bson.jar (692ms)\n",
      "downloading https://repo1.maven.org/maven2/org/mongodb/mongodb-driver-core/5.1.4/mongodb-driver-core-5.1.4.jar ...\n",
      "\t[SUCCESSFUL ] org.mongodb#mongodb-driver-core;5.1.4!mongodb-driver-core.jar (854ms)\n",
      "downloading https://repo1.maven.org/maven2/org/mongodb/bson-record-codec/5.1.4/bson-record-codec-5.1.4.jar ...\n",
      "\t[SUCCESSFUL ] org.mongodb#bson-record-codec;5.1.4!bson-record-codec.jar (426ms)\n",
      ":: resolution report :: resolve 7334ms :: artifacts dl 3364ms\n",
      "\t:: modules in use:\n",
      "\torg.mongodb#bson;5.1.4 from central in [default]\n",
      "\torg.mongodb#bson-record-codec;5.1.4 from central in [default]\n",
      "\torg.mongodb#mongodb-driver-core;5.1.4 from central in [default]\n",
      "\torg.mongodb#mongodb-driver-sync;5.1.4 from central in [default]\n",
      "\torg.mongodb.spark#mongo-spark-connector_2.12;10.5.0 from central in [default]\n",
      "\t---------------------------------------------------------------------\n",
      "\t|                  |            modules            ||   artifacts   |\n",
      "\t|       conf       | number| search|dwnlded|evicted|| number|dwnlded|\n",
      "\t---------------------------------------------------------------------\n",
      "\t|      default     |   5   |   5   |   5   |   0   ||   5   |   5   |\n",
      "\t---------------------------------------------------------------------\n",
      ":: retrieving :: org.apache.spark#spark-submit-parent-8802c274-e71f-489b-8925-31333f629444\n",
      "\tconfs: [default]\n",
      "\t5 artifacts copied, 0 already retrieved (2525kB/46ms)\n",
      "25/05/31 09:23:31 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    }
   ],
   "source": [
    "mongodb_uri =  os.getenv(\"MONGODB_URI\")\n",
    "\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"SaveJSONtoMongoDB\") \\\n",
    "    .config(\"spark.mongodb.read.connection.uri\", mongodb_uri) \\\n",
    "    .config(\"spark.mongodb.write.connection.uri\", mongodb_uri) \\\n",
    "    .config(\"spark.jars.packages\", \"org.mongodb.spark:mongo-spark-connector_2.12:10.5.0\") \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39fc7cc9",
   "metadata": {},
   "source": [
    "# BRONZE TABLE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ba7fce1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define LLM\n",
    "llm = ChatGoogleGenerativeAI(\n",
    "    model=\"gemini-2.0-flash\",\n",
    "    temperature=0,\n",
    "    max_tokens=None,\n",
    "    timeout=None,\n",
    "    max_retries=2\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13edbf69",
   "metadata": {},
   "source": [
    "## Resume Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "d154b6e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define models\n",
    "    \n",
    "class Experience(BaseModel):\n",
    "    role: Optional[str] = Field(None, description=\"The job title or position held\")\n",
    "    company: Optional[str] = Field(None, description=\"The name of the company\")\n",
    "    date_start: Optional[str] = Field(None, description=\"The start date of the job\")\n",
    "    date_end: Optional[str] = Field(None, description=\"The end date of the job, or 'current'/'present'/'ongoing' if specified\")\n",
    "    role_description: Optional[str] = Field(None, description=\"A description of the responsibilities and achievements in the role\")\n",
    "\n",
    "class Education(BaseModel):\n",
    "    degree: Optional[str] = Field(None, description=\"The academic degree obtained\")\n",
    "    institution: Optional[str] = Field(None, description=\"The name of the educational institution\")\n",
    "    date_start: Optional[str] = Field(None, description=\"The start date of the education program\")\n",
    "    date_end: Optional[str] = Field(None, description=\"The end date of the education program, or 'current'/'present'/'ongoing' if specified\")\n",
    "    grade: Optional[float] = Field(None, description=\"The GPA or final grade, if available\")\n",
    "    description: Optional[str] = Field(None, description=\"Additional details about the education\")\n",
    "\n",
    "class Resume(BaseModel):\n",
    "    name: Optional[str] = Field(None, description=\"Full name of the person\")\n",
    "    location_preference: Optional[str] = Field(None, description=\"Preference for their work location or remote, if stated\")\n",
    "    work_authorization: Optional[str] = Field(None, description=\"Work authorization that the person holds, such as citizenship, if stated\")\n",
    "    employment_type_preference: Optional[str] = Field(\n",
    "        None,\n",
    "        description=\"Type of employment the resume is looking for such as Full-time, Part-time, Contract, Freelance, or Internship, if stated\"\n",
    "    )\n",
    "    hard_skills: List[str] = Field(..., \n",
    "                                   description=\"A list of proficiencies in tools, technologies, frameworks, programming languages, platforms, methodologies, and key professional terms mentioned in the resume. \" \\\n",
    "                                   \"Avoid duplicates and use concise wording.\" \\\n",
    "                                   \"Clean up tool names and merge variations.\")\n",
    "    soft_skills: List[str] = Field(..., description=\"A list of soft skills mentioned in the resume, such as communication, teamwork, and leadership. Avoid duplication.\")\n",
    "    languages: List[str]= Field(..., description=\"A list of language proficiencies mentioned in the resume, excluding programming languages\")\n",
    "    experience: List[Experience] = Field(..., description=\"A list of past work experiences\")\n",
    "    education: List[Education] = Field(..., description=\"A list of educational qualifications\")\n",
    "    certifications: List[str] = Field(..., description=\"A list of certifications or licenses mentioned in the resume, such as AWS Certified Solutions Architect, PMP, etc.\")\n",
    "\n",
    "# Create the parser\n",
    "resume_parser = PydanticOutputParser(pydantic_object=Resume)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "e7bc4cbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the prompt\n",
    "resume_prompt_template = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"You are a helpful assistant that extracts structured information from resumes.\"),\n",
    "    (\"human\", \"Extract the following information from the resume:\\n\\n{text}\\n\\n{format_instructions}\")\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfd7233d",
   "metadata": {},
   "source": [
    "## Job Desc Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "f413bb0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define models for job desc\n",
    "\n",
    "class JD(BaseModel):\n",
    "    company_name: Optional[str] = Field(None, description=\"Name of the company posting the job\")\n",
    "    role_title: Optional[str] = Field(None, description=\"The title or name of the job role being offered\")\n",
    "    employment_type: Optional[str] = Field(None, description=\"Type of employment, such as Full-time, Part-time, Contract, Freelance, or Internship\")\n",
    "    about_the_company: Optional[str] = Field(None, description=\"A brief overview or description of the company\")\n",
    "    job_responsibilities: List[str] = Field(..., description=\"A list of key duties, tasks, or responsibilities associated with the job\")\n",
    "    required_hard_skills: List[str] = Field(..., description=\"A list of technical or hard skills required or preferred for the job\")\n",
    "    required_soft_skills: List[str] = Field(..., description=\"A list of soft skills or character required or preferred for the job\")\n",
    "    required_language_proficiencies: List[str] = Field(..., description=\"A list of language proficiencies required for the job, excluding programming languages\")\n",
    "    required_work_authorization: Optional[str] = Field(None, description=\"Work authorization required for the job\")\n",
    "    required_education: Optional[str] = Field(None, description=\"The minimum educational qualification required for the job, such as a degree or certification\")\n",
    "    job_location: Optional[str] = Field(None, description=\"Location where the job is based, such as a city or remote\")\n",
    "    date_posted: Optional[datetime.datetime] = Field(None, description=\"The date that the job is posted\")\n",
    "\n",
    "# Create the parser\n",
    "jd_parser = PydanticOutputParser(pydantic_object=JD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "aba4865c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the prompt\n",
    "jd_prompt_template = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"You are a helpful assistant that extracts structured information from job descriptions.\"),\n",
    "    (\"human\", \"Extract the following information from the job description:\\n\\n{text}\\n\\n{format_instructions}\")\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50d2cac6",
   "metadata": {},
   "source": [
    "## Parse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "e289d7bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a function to parse text with llm\n",
    "def parse_with_llm(text, prompt_template, parser, llm):\n",
    "    prompt = prompt_template.format_messages(\n",
    "        text=text,\n",
    "        format_instructions=parser.get_format_instructions()\n",
    "    )\n",
    "    \n",
    "    response = llm.invoke(prompt)\n",
    "    return parser.parse(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17cb440d",
   "metadata": {},
   "source": [
    "### Parse resume"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ef3eaf93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SummaryFull stack Software Engineer with 8+ years of experience in software industry. Professional, creative, responsible with proven analytical skills and knowledge of Microsoft .Net platform and PHP. Passionate about new technologies and software development. Fast learner, focused, problem solver, great Team Player, and lover of good software development practices including Systems Development Life Cycle (SDLC).\n",
      "HighlightsC#, PHP.Technologies/Services: ASP.NET, ASP.NET MVC, ASP.NET Web API, EF, ADO.NET, T-SQL, .NET Framework, LINQ, Razor, Hangfire, SignalR, HTML, HTML5, XML, CSS, CSS3, JSON, AJAX, jQuery, AngularJS, Bootstrap, SOAP, REST, Alfresco ECM, Alfresco Activiti BPM, Alfresco OCR, OCR, Tesseract, AWS S3, AWS EC2, CodeIgniter, Composer, Google Maps API, Apache Web Server, Apache Tomcat, PL/pgSQL, LaTeX.Databases: MS SQL Server, PostgreSQL, MySQL.Source Code Control: SVN, GIT.Project Management Tool: Redmine, Gforge.IDEs: Visual Studio, PhpStorm, Netbeans, Intellij Idea, Zend Studio.Operating Systems: Microsoft Windows, GNU/Linux.Methodologies & Standards: Scrum, RUP, XP, DIRKS, ISAD (G), ISO 15489.\n",
      "ExperienceSoftware Developer,04/2016-09/2016–Peoria,,EcuadorModeled process using BPM, workflows for a Help Desk Module in Alfresco Activiti BPM.Designed and created de Alfresco Content Model for the Help Desk Module.Developed using XML, Javascript, Alfresco REST Web Services, jQuery, Bootstrap and Freemarker the workflows modeled.Integrated Alfresco ECM with Microsoft Office and WebDav protocol.Software .Net Developer,01/2015-04/2016–City,,EcuadorDeveloped using C#, ASP.NET MVC, ASP.NET Web API, ADO.NET .NET Framework, EF, LINQ, SQL Server, Hangfire, SignalR, MS SQL Server, T-SQL, AngularJS, jQuery, HTML5, CSS3, and MySQL a large-scale parking system from scratch.Rewrote and redesigned a poorly parking system implemented in Node.js.Rewrote the entire backend in C# and the frontend in ASP.NET MVC, ASP.NET Web API, AngularJS, jQuery, JavaScript, and Bootstrap to be more user friendly.Developed using Hangfire to perform with .NET job scheduling, and SignalR to create a real-time application which allowed bi-directional communication between server and client.Created a sync job which listened to the records of a sensor in a MySQL database and synchronized them in a MS SQL Server database and showed real-time results in a dashboard.Developed using PHP, JasperReports for PHP REST Web Service API, MySQL, AngularJS, jQuery, HTML5, CSS3 and, Bootstrap a Report Module to integrate it into a police management system.Coded using PL/pgSQL several queries to compare and recover millions of damaged records.Software Engineer and Professor,09/2008-11/2014Newport Group–City,,CubaDeveloped using PHP5, HTML, CSS, JavaScript, Drupal, jQuery, AJAX, JSON, MySQL and, XML-RPC an Intranet.Developed using Alfresco ECM, Alfresco REST API, PHP, XML, HTML, CSS, JavaScript, CodeIgniter, jQuery, PostgreSQL and, Lucene the modules File Sharing and Audit Log for a Document Management System.Integrated Alfresco ECM with OpenOffice.org.Developed using PHP, HTML5, CSS3, JavaScript, jQuery, AJAX, JSON, and, PostgreSQL the Dashboard and Report Management modules.Developed using Alfresco ECM, Activiti, REST Web Services, Freemarker, HTML, CSS3, LESS CSS, JavaScript, jQuery, AJAX, JSON PostgreSQL and, Lucene the modules Records Management, Classification Table Management, Task Management, Data List, Dashboard and, Project Files Management for different versions of a Document Management System.Performed Requirements Specification, Analysis and Design, and Test Case Design.Customized using Freemarker, Bootstrap, LESS CSS, XML and, JavaScript a Theme for Alfresco Share.Coded using XML, Content Models for Alfresco ECM.Interacted with clients to identify Business Requirements.Provided training courses for clients.Products and projects:\n",
      "Product: Document Management System eXcriba v3.0 (2013-2014, Patent 2127-7-2014).Client: Development Centers of University of Informatics Sciences, Havana Cuba.Product: Quipus, Document Management System v1.0 (2012-2013, Patent 196-2012).Client: General Archive of the Nation of Venezuela.Product: Document Management System AvilaDOC (2009-2010).Client: Ministry of Interior and Justice of Venezuela.Product: Document Management System eXcriba v1.0 (2008-2010, Patent 2868-2010), v2.0 (2010-2011, Patent 2378-2011).Client: Development Centers of University of Informatics Sciences, Havana Cuba.Client: General Customs of the Republic of Cuba.Client: Ministry of Informatics and Communications of Cuba.\n",
      "EducationBS:Computer Science,Expected in2008-University of Informatics Sciences-Havana,GPA:Status-Computer ScienceDegree:Accounting,Expected in2003-Higher Pedagogical Institute-,GuantanamoGPA:Status-Accounting\n",
      "Skills.NET, ASP.NET, ADO, AJAX, Apache, Apache Web Server, API, bi, Content, CSS, CSS3, Client, clients, Databases, database, Document Management, Drupal, English, XML, Help Desk, HTML, HTML5, PHP, PHP5, ISO, JavaScript, jQuery, JSON, Linux, C#, Microsoft Office, Microsoft Windows, MVC, MySQL, Composer, OCR, Operating Systems, PL, police, PostgreSQL, Programming, Project Management, real-time, RUP, scheduling, Scrum, SOAP, Software Engineering, Spanish, Specification, MS SQL Server, SQL Server, System v1.0, Tomcat, T-SQL, Visual Studio\n"
     ]
    }
   ],
   "source": [
    "print(df['resume_text'].iloc[6240])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "e9e7d30f",
   "metadata": {},
   "outputs": [],
   "source": [
    "parsed_resume = parse_with_llm(df['resume_text'].iloc[6240], resume_prompt_template, resume_parser, llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "73d61c1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"name\": null,\n",
      "  \"location_preference\": null,\n",
      "  \"work_authorization\": null,\n",
      "  \"employment_type_preference\": null,\n",
      "  \"hard_skills\": [\n",
      "    \"C#\",\n",
      "    \"PHP\",\n",
      "    \"ASP.NET\",\n",
      "    \"ASP.NET MVC\",\n",
      "    \"ASP.NET Web API\",\n",
      "    \"Entity Framework\",\n",
      "    \"ADO.NET\",\n",
      "    \"T-SQL\",\n",
      "    \".NET Framework\",\n",
      "    \"LINQ\",\n",
      "    \"Razor\",\n",
      "    \"Hangfire\",\n",
      "    \"SignalR\",\n",
      "    \"HTML\",\n",
      "    \"HTML5\",\n",
      "    \"XML\",\n",
      "    \"CSS\",\n",
      "    \"CSS3\",\n",
      "    \"JSON\",\n",
      "    \"AJAX\",\n",
      "    \"jQuery\",\n",
      "    \"AngularJS\",\n",
      "    \"Bootstrap\",\n",
      "    \"SOAP\",\n",
      "    \"REST\",\n",
      "    \"Alfresco ECM\",\n",
      "    \"Alfresco Activiti BPM\",\n",
      "    \"Alfresco OCR\",\n",
      "    \"OCR\",\n",
      "    \"Tesseract\",\n",
      "    \"AWS S3\",\n",
      "    \"AWS EC2\",\n",
      "    \"CodeIgniter\",\n",
      "    \"Composer\",\n",
      "    \"Google Maps API\",\n",
      "    \"Apache Web Server\",\n",
      "    \"Apache Tomcat\",\n",
      "    \"PL/pgSQL\",\n",
      "    \"LaTeX\",\n",
      "    \"MS SQL Server\",\n",
      "    \"PostgreSQL\",\n",
      "    \"MySQL\",\n",
      "    \"SVN\",\n",
      "    \"GIT\",\n",
      "    \"Redmine\",\n",
      "    \"Gforge\",\n",
      "    \"Visual Studio\",\n",
      "    \"PhpStorm\",\n",
      "    \"Netbeans\",\n",
      "    \"Intellij Idea\",\n",
      "    \"Zend Studio\",\n",
      "    \"Microsoft Windows\",\n",
      "    \"GNU/Linux\",\n",
      "    \"Scrum\",\n",
      "    \"RUP\",\n",
      "    \"XP\",\n",
      "    \"DIRKS\",\n",
      "    \"ISAD (G)\",\n",
      "    \"ISO 15489\",\n",
      "    \"Drupal\",\n",
      "    \"Lucene\",\n",
      "    \"LESS CSS\",\n",
      "    \"Javascript\",\n",
      "    \"JasperReports\"\n",
      "  ],\n",
      "  \"soft_skills\": [\n",
      "    \"Analytical Skills\",\n",
      "    \"Problem Solver\",\n",
      "    \"Team Player\",\n",
      "    \"Fast Learner\",\n",
      "    \"Focused\",\n",
      "    \"Creative\",\n",
      "    \"Responsible\"\n",
      "  ],\n",
      "  \"languages\": [\n",
      "    \"English\",\n",
      "    \"Spanish\"\n",
      "  ],\n",
      "  \"experience\": [\n",
      "    {\n",
      "      \"role\": \"Software Developer\",\n",
      "      \"company\": \"Peoria\",\n",
      "      \"date_start\": \"2016-04-01T00:00:00\",\n",
      "      \"date_end\": \"2016-09-01\",\n",
      "      \"role_description\": \"Modeled process using BPM, workflows for a Help Desk Module in Alfresco Activiti BPM.\\nDesigned and created de Alfresco Content Model for the Help Desk Module.\\nDeveloped using XML, Javascript, Alfresco REST Web Services, jQuery, Bootstrap and Freemarker the workflows modeled.\\nIntegrated Alfresco ECM with Microsoft Office and WebDav protocol.\"\n",
      "    },\n",
      "    {\n",
      "      \"role\": \"Software .Net Developer\",\n",
      "      \"company\": \"City\",\n",
      "      \"date_start\": \"2015-01-01T00:00:00\",\n",
      "      \"date_end\": \"2016-04-01\",\n",
      "      \"role_description\": \"Developed using C#, ASP.NET MVC, ASP.NET Web API, ADO.NET .NET Framework, EF, LINQ, SQL Server, Hangfire, SignalR, MS SQL Server, T-SQL, AngularJS, jQuery, HTML5, CSS3, and MySQL a large-scale parking system from scratch.\\nRewrote and redesigned a poorly parking system implemented in Node.js.\\nRewrote the entire backend in C# and the frontend in ASP.NET MVC, ASP.NET Web API, AngularJS, jQuery, JavaScript, and Bootstrap to be more user friendly.\\nDeveloped using Hangfire to perform with .NET job scheduling, and SignalR to create a real-time application which allowed bi-directional communication between server and client.\\nCreated a sync job which listened to the records of a sensor in a MySQL database and synchronized them in a MS SQL Server database and showed real-time results in a dashboard.\\nDeveloped using PHP, JasperReports for PHP REST Web Service API, MySQL, AngularJS, jQuery, HTML5, CSS3 and, Bootstrap a Report Module to integrate it into a police management system.\\nCoded using PL/pgSQL several queries to compare and recover millions of damaged records.\"\n",
      "    },\n",
      "    {\n",
      "      \"role\": \"Software Engineer and Professor\",\n",
      "      \"company\": \"Newport Group\",\n",
      "      \"date_start\": \"2008-09-01T00:00:00\",\n",
      "      \"date_end\": \"2014-11-01\",\n",
      "      \"role_description\": \"Developed using PHP5, HTML, CSS, JavaScript, Drupal, jQuery, AJAX, JSON, MySQL and, XML-RPC an Intranet.\\nDeveloped using Alfresco ECM, Alfresco REST API, PHP, XML, HTML, CSS, JavaScript, CodeIgniter, jQuery, PostgreSQL and, Lucene the modules File Sharing and Audit Log for a Document Management System.\\nIntegrated Alfresco ECM with OpenOffice.org.\\nDeveloped using PHP, HTML5, CSS3, JavaScript, jQuery, AJAX, JSON, and, PostgreSQL the Dashboard and Report Management modules.\\nDeveloped using Alfresco ECM, Activiti, REST Web Services, Freemarker, HTML, CSS3, LESS CSS, JavaScript, jQuery, AJAX, JSON PostgreSQL and, Lucene the modules Records Management, Classification Table Management, Task Management, Data List, Dashboard and, Project Files Management for different versions of a Document Management System.\\nPerformed Requirements Specification, Analysis and Design, and Test Case Design.\\nCustomized using Freemarker, Bootstrap, LESS CSS, XML and, JavaScript a Theme for Alfresco Share.\\nCoded using XML, Content Models for Alfresco ECM.\\nInteracted with clients to identify Business Requirements.\\nProvided training courses for clients.\"\n",
      "    }\n",
      "  ],\n",
      "  \"education\": [\n",
      "    {\n",
      "      \"degree\": \"Computer Science\",\n",
      "      \"institution\": \"University of Informatics Sciences-Havana\",\n",
      "      \"date_start\": \"2008-01-01T00:00:00\",\n",
      "      \"date_end\": null,\n",
      "      \"grade\": null,\n",
      "      \"description\": null\n",
      "    },\n",
      "    {\n",
      "      \"degree\": \"Accounting\",\n",
      "      \"institution\": \"Higher Pedagogical Institute-\",\n",
      "      \"date_start\": \"2003-01-01T00:00:00\",\n",
      "      \"date_end\": null,\n",
      "      \"grade\": null,\n",
      "      \"description\": null\n",
      "    }\n",
      "  ],\n",
      "  \"certifications\": []\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print(parsed_resume.model_dump_json(indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "143dea9a",
   "metadata": {},
   "source": [
    "### Parse job desc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c1b7e767",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hi,\n",
      "Hope you are doing great today. Please find the job description below. Let me know your job interest as soon as possible. I will highly appreciate it if you can refer somebody suitable for this position. \n",
      "Role: Data Engineer (Oracle and DataStage).Location: RemoteContract Position\n",
      "Job Description:RoleResponsibilities:Skills: Oracle, Datastage, UNIX, PLSQL, SQL. Good to have: AWS, Matillion, Snowflake. Data engineering experience; expert level experience with SQL. Experience with the cloud (AWS, Azure andor Google Cloud Platform).  Experience in cloud-based data warehouses (Snowflake, Google BigQuery, Amazon Redshift, Azure Synapse Analytics).  Experience with cloud-based ETLELT tools (Matillion, Glue, Data Factory) and data modelling.  Experience with version control systems (Git, SVN).  Understanding of and willingness to embrace Agile Principles. \n",
      "Looking forward to your response . \n",
      "Shubhanshu Tripathishubhanshu.t@cblsolutions.com 469-947-7816 (Ext  209)Cerebral Technologies, Inc (D.B.A CBLSolutions) http:cblsolutions.com400 E Royal Lane, Ste 235, Irving, TX - 75039 Linkedin: https:www.linkedin.cominshubhanshu-tripathi-058228213 \n"
     ]
    }
   ],
   "source": [
    "print(df['job_description_text'].iloc[6236])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "57dd896e",
   "metadata": {},
   "outputs": [],
   "source": [
    "parsed_jd = parse_with_llm(df['job_description_text'].iloc[6236], jd_prompt_template, jd_parser, llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a3fefe66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"company_name\": \"Cerebral Technologies, Inc\",\n",
      "  \"role_title\": \"Data Engineer (Oracle and DataStage)\",\n",
      "  \"employment_type\": \"Contract\",\n",
      "  \"about_the_company\": null,\n",
      "  \"job_responsibilities\": [\n",
      "    \"Data engineering experience\",\n",
      "    \"Experience with the cloud (AWS, Azure andor Google Cloud Platform)\",\n",
      "    \"Experience in cloud-based data warehouses (Snowflake, Google BigQuery, Amazon Redshift, Azure Synapse Analytics)\",\n",
      "    \"Experience with cloud-based ETLELT tools (Matillion, Glue, Data Factory) and data modelling\",\n",
      "    \"Experience with version control systems (Git, SVN)\",\n",
      "    \"Understanding of and willingness to embrace Agile Principles\"\n",
      "  ],\n",
      "  \"required_hard_skills\": [\n",
      "    \"Oracle\",\n",
      "    \"Datastage\",\n",
      "    \"UNIX\",\n",
      "    \"PLSQL\",\n",
      "    \"SQL\",\n",
      "    \"AWS\",\n",
      "    \"Matillion\",\n",
      "    \"Snowflake\",\n",
      "    \"SQL\",\n",
      "    \"AWS\",\n",
      "    \"Azure\",\n",
      "    \"Google Cloud Platform\",\n",
      "    \"Snowflake\",\n",
      "    \"Google BigQuery\",\n",
      "    \"Amazon Redshift\",\n",
      "    \"Azure Synapse Analytics\",\n",
      "    \"Matillion\",\n",
      "    \"Glue\",\n",
      "    \"Data Factory\",\n",
      "    \"Git\",\n",
      "    \"SVN\"\n",
      "  ],\n",
      "  \"required_soft_skills\": [\n",
      "    \"Agile Principles\"\n",
      "  ],\n",
      "  \"required_language_proficiencies\": [],\n",
      "  \"required_work_authorization\": null,\n",
      "  \"required_education\": null,\n",
      "  \"job_location\": \"Remote\",\n",
      "  \"date_posted\": null\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print(parsed_jd.model_dump_json(indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b5b71f4",
   "metadata": {},
   "source": [
    "### Parse & save into DB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b5fbce08",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>resume_text</th>\n",
       "      <th>job_description_text</th>\n",
       "      <th>label</th>\n",
       "      <th>resume_id</th>\n",
       "      <th>job_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SummaryHighly motivated Sales Associate with e...</td>\n",
       "      <td>Net2Source Inc. is an award-winning total work...</td>\n",
       "      <td>No Fit</td>\n",
       "      <td>RES_QDvgj241</td>\n",
       "      <td>JD_QDvgj241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Professional SummaryCurrently working with Cat...</td>\n",
       "      <td>At Salas OBrien we tell our clients that were ...</td>\n",
       "      <td>No Fit</td>\n",
       "      <td>RES_tvKW28PW</td>\n",
       "      <td>JD_tvKW28PW</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SummaryI started my construction career in Jun...</td>\n",
       "      <td>Schweitzer Engineering Laboratories (SEL) Infr...</td>\n",
       "      <td>No Fit</td>\n",
       "      <td>RES_Pg6ipOr5</td>\n",
       "      <td>JD_Pg6ipOr5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SummaryCertified Electrical Foremanwith thirte...</td>\n",
       "      <td>Mizick Miller &amp; Company, Inc. is looking for a...</td>\n",
       "      <td>No Fit</td>\n",
       "      <td>RES_O5bebNRA</td>\n",
       "      <td>JD_O5bebNRA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SummaryWith extensive experience in business/r...</td>\n",
       "      <td>Life at Capgemini\\nCapgemini supports all aspe...</td>\n",
       "      <td>No Fit</td>\n",
       "      <td>RES_JWSvWYY5</td>\n",
       "      <td>JD_JWSvWYY5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6236</th>\n",
       "      <td>SummaryResults-driven Data Entry Clerk with ex...</td>\n",
       "      <td>Hi,\\nHope you are doing great today. Please fi...</td>\n",
       "      <td>Good Fit</td>\n",
       "      <td>RES_vNEJ62Py</td>\n",
       "      <td>JD_vNEJ62Py</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6237</th>\n",
       "      <td>Professional SummaryWith the attitude of learn...</td>\n",
       "      <td>Job Title: DHT - Front End Software Engineer W...</td>\n",
       "      <td>Good Fit</td>\n",
       "      <td>RES_DPqh0lVb</td>\n",
       "      <td>JD_DPqh0lVb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6238</th>\n",
       "      <td>Summary•        \\nOver\\nThree years of extensi...</td>\n",
       "      <td>LHH Recruitment Solutions is looking for a Sof...</td>\n",
       "      <td>Good Fit</td>\n",
       "      <td>RES_1HWrRA5T</td>\n",
       "      <td>JD_1HWrRA5T</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6239</th>\n",
       "      <td>ProfileAbility to prioritize and multi-task in...</td>\n",
       "      <td>Our client is a growing Medical Device company...</td>\n",
       "      <td>Good Fit</td>\n",
       "      <td>RES_XdUNowSD</td>\n",
       "      <td>JD_XdUNowSD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6240</th>\n",
       "      <td>SummaryFull stack Software Engineer with 8+ ye...</td>\n",
       "      <td>Robert Half is looking for a Senior Full Stack...</td>\n",
       "      <td>Good Fit</td>\n",
       "      <td>RES_2RPwzELC</td>\n",
       "      <td>JD_2RPwzELC</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            resume_text  \\\n",
       "0     SummaryHighly motivated Sales Associate with e...   \n",
       "1     Professional SummaryCurrently working with Cat...   \n",
       "2     SummaryI started my construction career in Jun...   \n",
       "3     SummaryCertified Electrical Foremanwith thirte...   \n",
       "4     SummaryWith extensive experience in business/r...   \n",
       "6236  SummaryResults-driven Data Entry Clerk with ex...   \n",
       "6237  Professional SummaryWith the attitude of learn...   \n",
       "6238  Summary•        \\nOver\\nThree years of extensi...   \n",
       "6239  ProfileAbility to prioritize and multi-task in...   \n",
       "6240  SummaryFull stack Software Engineer with 8+ ye...   \n",
       "\n",
       "                                   job_description_text     label  \\\n",
       "0     Net2Source Inc. is an award-winning total work...    No Fit   \n",
       "1     At Salas OBrien we tell our clients that were ...    No Fit   \n",
       "2     Schweitzer Engineering Laboratories (SEL) Infr...    No Fit   \n",
       "3     Mizick Miller & Company, Inc. is looking for a...    No Fit   \n",
       "4     Life at Capgemini\\nCapgemini supports all aspe...    No Fit   \n",
       "6236  Hi,\\nHope you are doing great today. Please fi...  Good Fit   \n",
       "6237  Job Title: DHT - Front End Software Engineer W...  Good Fit   \n",
       "6238  LHH Recruitment Solutions is looking for a Sof...  Good Fit   \n",
       "6239  Our client is a growing Medical Device company...  Good Fit   \n",
       "6240  Robert Half is looking for a Senior Full Stack...  Good Fit   \n",
       "\n",
       "         resume_id       job_id  \n",
       "0     RES_QDvgj241  JD_QDvgj241  \n",
       "1     RES_tvKW28PW  JD_tvKW28PW  \n",
       "2     RES_Pg6ipOr5  JD_Pg6ipOr5  \n",
       "3     RES_O5bebNRA  JD_O5bebNRA  \n",
       "4     RES_JWSvWYY5  JD_JWSvWYY5  \n",
       "6236  RES_vNEJ62Py  JD_vNEJ62Py  \n",
       "6237  RES_DPqh0lVb  JD_DPqh0lVb  \n",
       "6238  RES_1HWrRA5T  JD_1HWrRA5T  \n",
       "6239  RES_XdUNowSD  JD_XdUNowSD  \n",
       "6240  RES_2RPwzELC  JD_2RPwzELC  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_subset = pd.concat([df[:5], df[-5:]])\n",
    "df_subset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "616c186f",
   "metadata": {},
   "source": [
    "Parse JDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "5b24e97e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [01:36<00:00,  9.62s/it]\n"
     ]
    }
   ],
   "source": [
    "parsed_resumes = []\n",
    "parsed_jds = []\n",
    "\n",
    "for idx, row in tqdm(df_subset.iterrows(), total=len(df_subset)):\n",
    "    resume_text = row['resume_text']\n",
    "    jd_text = row['job_description_text']\n",
    "    try:\n",
    "        # Process resume\n",
    "        parsed_resume = parse_with_llm(resume_text, resume_prompt_template, resume_parser, llm)\n",
    "        parsed_resume_dict = parsed_resume.model_dump(mode=\"json\")\n",
    "        parsed_resume_dict = {**parsed_resume_dict, \n",
    "                            #   'snapshot_date': row['snapshot_date'], \n",
    "                              'id': row['resume_id']}\n",
    "        parsed_resumes.append(parsed_resume_dict)\n",
    "\n",
    "        # save as json\n",
    "        resume_output_path = os.path.join('examples', 'resume', f\"{idx}.json\")\n",
    "        with open(resume_output_path, \"w\") as f:\n",
    "            json.dump(parsed_resume_dict, f, indent=2)\n",
    "\n",
    "        # Process JD\n",
    "        parsed_jd = parse_with_llm(jd_text, jd_prompt_template, jd_parser, llm)\n",
    "        parsed_jd_dict = parsed_jd.model_dump(mode=\"json\")\n",
    "        parsed_jd_dict = {**parsed_jd_dict, \n",
    "                        #   'snapshot_date': row['snapshot_date'],\n",
    "                          'id': row['job_id']}\n",
    "        parsed_jds.append(parsed_jd_dict)\n",
    "\n",
    "        # save as json\n",
    "        jd_output_path = os.path.join('examples', 'jd', f\"{idx}.json\")\n",
    "        with open(jd_output_path, \"w\") as f:\n",
    "            json.dump(parsed_jd_dict, f, indent=2)\n",
    "       \n",
    "    except Exception as e:\n",
    "        print(f\"Error parsing row {idx}: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04d3d83a",
   "metadata": {},
   "source": [
    "Convert into PySpark Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "903ec600",
   "metadata": {},
   "outputs": [],
   "source": [
    "def python_type_to_spark_type(annotation):\n",
    "    origin = get_origin(annotation)\n",
    "\n",
    "    if origin is Union:  # Handle Optional\n",
    "        args = [arg for arg in get_args(annotation) if arg is not type(None)]\n",
    "        return python_type_to_spark_type(args[0])\n",
    "\n",
    "    if origin in (list, List):\n",
    "        element_type = python_type_to_spark_type(get_args(annotation)[0])\n",
    "        return ArrayType(element_type)\n",
    "\n",
    "    if isinstance(annotation, type):\n",
    "        if issubclass(annotation, BaseModel):\n",
    "            return pydantic_to_spark_schema(annotation)\n",
    "        if issubclass(annotation, str):\n",
    "            return StringType()\n",
    "        if issubclass(annotation, int):\n",
    "            return IntegerType()\n",
    "        if issubclass(annotation, float):\n",
    "            return FloatType()\n",
    "        if issubclass(annotation, bool):\n",
    "            return BooleanType()\n",
    "        if issubclass(annotation, datetime.datetime):\n",
    "            return StringType()\n",
    "\n",
    "    return StringType()\n",
    "\n",
    "def pydantic_to_spark_schema(model: type) -> StructType:\n",
    "    fields = []\n",
    "\n",
    "    for name, field in model.model_fields.items():\n",
    "        annotation = field.annotation\n",
    "\n",
    "        spark_type = python_type_to_spark_type(annotation)\n",
    "        fields.append(StructField(name, spark_type, True))  # assume all nullable\n",
    "    fields.append(StructField('snapshot_date', StringType(), True))\n",
    "    fields.append(StructField('id', StringType(), True))\n",
    "\n",
    "    return StructType(fields)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "30d87e8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "resume_df = spark.createDataFrame(parsed_resumes, schema=pydantic_to_spark_schema(Resume))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "6c0b2b52",
   "metadata": {},
   "outputs": [],
   "source": [
    "jd_df = spark.createDataFrame(parsed_jds, schema=pydantic_to_spark_schema(JD))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a53be5a",
   "metadata": {},
   "source": [
    "Save into DB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "753e182e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "resume_df.write.format(\"mongodb\") \\\n",
    "               .mode(\"overwrite\") \\\n",
    "               .option(\"database\", \"jobmirror\") \\\n",
    "               .option(\"collection\", \"resume\") \\\n",
    "               .save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "0c7686bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "jd_df.write.format(\"mongodb\") \\\n",
    "               .mode(\"overwrite\") \\\n",
    "               .option(\"database\", \"jobmirror\") \\\n",
    "               .option(\"collection\", \"jd\") \\\n",
    "               .save()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f185d77",
   "metadata": {},
   "source": [
    "# SILVER"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "932a8a66",
   "metadata": {},
   "source": [
    "# GOLD"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72c5416e",
   "metadata": {},
   "source": [
    "## Get scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "52d6567a",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_model = GoogleGenerativeAIEmbeddings(\n",
    "    model=\"models/text-embedding-004\", task_type=\"SEMANTIC_SIMILARITY\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "1f948ccd",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings_required_skills = embedding_model.embed_documents(parsed_jd.required_hard_skills)\n",
    "embeddings_skills_owned = embedding_model.embed_documents(parsed_resume.hard_skills)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "93af6e52",
   "metadata": {},
   "outputs": [],
   "source": [
    "required_skills = np.array(embeddings_required_skills)\n",
    "skills_owned = np.array(embeddings_skills_owned)\n",
    "\n",
    "# Normalize embeddings to unit vectors (L2 norm)\n",
    "required_skills = required_skills / np.linalg.norm(required_skills, axis=1, keepdims=True)\n",
    "skills_owned = skills_owned / np.linalg.norm(skills_owned, axis=1, keepdims=True)\n",
    "\n",
    "# Compute cosine similarity matrix by dot product\n",
    "similarity_matrix = np.dot(required_skills, skills_owned.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "4ae5fdef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Required: PostgreSQL  <=> Best Owned: PostgreSQL  | Similarity: 1.00\n",
      "Required: Express  <=> Best Owned: EF  | Similarity: 0.63\n",
      "Required: React  <=> Best Owned: HTML5  | Similarity: 0.63\n",
      "Required: NodeJS  <=> Best Owned: AngularJS  | Similarity: 0.73\n",
      "Required: Redux  <=> Best Owned: Redmine  | Similarity: 0.63\n",
      "Required: HTML  <=> Best Owned: HTML  | Similarity: 1.00\n",
      "Required: CSS  <=> Best Owned: CSS  | Similarity: 1.00\n",
      "Required: JavaScript  <=> Best Owned: jQuery  | Similarity: 0.86\n",
      "Required: JSON  <=> Best Owned: JSON  | Similarity: 1.00\n",
      "Required: Git  <=> Best Owned: GIT  | Similarity: 0.95\n",
      "Required: REST  <=> Best Owned: REST  | Similarity: 1.00\n",
      "Required: Firebase  <=> Best Owned: Hangfire  | Similarity: 0.62\n",
      "Required: Material-UI  <=> Best Owned: AngularJS  | Similarity: 0.63\n",
      "Required: D3js  <=> Best Owned: jQuery  | Similarity: 0.72\n",
      "Required: Docker (Compose)  <=> Best Owned: Composer  | Similarity: 0.67\n",
      "Required: AWS  <=> Best Owned: AWS EC2  | Similarity: 0.85\n"
     ]
    }
   ],
   "source": [
    "best_matches = []\n",
    "\n",
    "for i, req_skill in enumerate(parsed_jd.required_hard_skills):\n",
    "    j = similarity_matrix[i].argmax()\n",
    "    score = similarity_matrix[i, j]\n",
    "    if score >= 0.6:\n",
    "        best_matches.append((req_skill, parsed_resume.hard_skills[j], score))\n",
    "\n",
    "# Print\n",
    "for req_skill, own_skill, score in best_matches:\n",
    "    print(f\"Required: {req_skill}  <=> Best Owned: {own_skill}  | Similarity: {score:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "991dbf3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings_role_name = embedding_model.embed_query(parsed_jd.role_title)\n",
    "embeddings_experience_titles = embedding_model.embed_documents([exp.role for exp in parsed_resume.experience])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "65b9e94a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Senior Full Stack Engineer (PERN Stack)'"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parsed_jd.role_title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "b4e5d683",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Software Developer',\n",
       " 'Software .Net Developer',\n",
       " 'Software Engineer and Professor']"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[exp.role for exp in parsed_resume.experience]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "31d693a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "role_name = np.array(embeddings_role_name)\n",
    "experiences = np.array(embeddings_experience_titles)\n",
    "\n",
    "# Normalize embeddings to unit vectors (L2 norm)\n",
    "role_name = role_name / np.linalg.norm(role_name)\n",
    "experiences = experiences / np.linalg.norm(experiences, axis=1, keepdims=True)\n",
    "\n",
    "# Compute cosine similarity matrix by dot product\n",
    "similarity_matrix = np.dot(experiences, role_name.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "e5a979df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.65028087, 0.62905722, 0.6121288 ])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "similarity_matrix"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
